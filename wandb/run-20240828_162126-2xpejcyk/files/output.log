> /vast/palmer/pi/krishnaswamy_smita/sv496/PointCloudNet/models/graph_learning.py(100)forward()
-> W = 1/(W + eps)
tensor([[0.0000e+00, 1.4394e+02, 1.6898e+02,  ..., 1.7750e+02, 1.6131e+02,
         2.0130e+02],
        [1.4394e+02, 1.2500e-01, 1.9491e+02,  ..., 1.2091e+02, 1.6681e+02,
         1.3496e+02],
        [1.6898e+02, 1.9491e+02, 0.0000e+00,  ..., 2.2871e+02, 1.6818e+02,
         2.5106e+02],
        ...,
        [1.7750e+02, 1.2091e+02, 2.2871e+02,  ..., 0.0000e+00, 1.9752e+02,
         1.3883e+02],
        [1.6131e+02, 1.6681e+02, 1.6818e+02,  ..., 1.9752e+02, 1.2500e-01,
         2.0290e+02],
        [2.0130e+02, 1.3496e+02, 2.5106e+02,  ..., 1.3883e+02, 2.0290e+02,
         0.0000e+00]], device='cuda:0', grad_fn=<ViewBackward0>)
*** NameError: name 'matrix' is not defined
tensor(False, device='cuda:0')
tensor([0.0000, 0.1250, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0884,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0884, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1531, 0.0000, 0.0000, 0.0000,
        0.1531, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0884,
        0.0000, 0.0000, 0.1250, 0.0884, 0.0884, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000,
        0.0000, 0.0884, 0.0000, 0.0884, 0.0000, 0.0625, 0.1250, 0.0000, 0.0000,
        0.0000, 0.1250, 0.0625, 0.0884, 0.0884, 0.0884, 0.1250, 0.0884, 0.0000,
        0.1250, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1250,
        0.0884, 0.0000, 0.0884, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.1250, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000, 0.0000, 0.0884, 0.0000,
        0.1250, 0.0000, 0.0000, 0.0000, 0.0884, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0884, 0.0884, 0.0000, 0.0000, 0.1531,
        0.0000, 0.0000, 0.0000, 0.1250, 0.1976, 0.0000, 0.0884, 0.0884, 0.0000,
        0.0884, 0.0000, 0.0000, 0.0884, 0.1250, 0.0000, 0.0000, 0.0000, 0.1250,
        0.0000, 0.0884, 0.1250, 0.0000, 0.0000, 0.0884, 0.0000, 0.0000, 0.0000,
        0.0884, 0.0000, 0.0000, 0.1250, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0884, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0884, 0.0000, 0.0000, 0.0884, 0.0000, 0.0000, 0.0000, 0.1531,
        0.1250, 0.1250, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1250, 0.0000,
        0.0884, 0.0884, 0.0000, 0.0000, 0.1250, 0.0000, 0.0884, 0.1250, 0.0000,
        0.0000, 0.0884, 0.0000, 0.0000, 0.0000, 0.0884, 0.0000, 0.0884, 0.0000,
        0.0884, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.1250, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0884, 0.1250, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0884, 0.0884, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0884, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0884, 0.1250, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0884, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0884,
        0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0884, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0884, 0.0884, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0884, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.1250, 0.1250, 0.0000, 0.1250, 0.0884, 0.1250, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.1768, 0.0884, 0.0000, 0.0000, 0.0000, 0.0884,
        0.0000, 0.0000, 0.1250, 0.0884, 0.0000, 0.0000, 0.0000, 0.0000, 0.0884,
        0.1250, 0.0884, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0884, 0.0000, 0.0000, 0.1768,
        0.0000, 0.1531, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1531,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1250, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0884, 0.0000, 0.0000, 0.1250, 0.0000, 0.1250, 0.0000,
        0.0000, 0.0884, 0.0000, 0.1768, 0.0000, 0.0000, 0.1531, 0.0000, 0.0884,
        0.0625, 0.0000, 0.0000, 0.0000, 0.0884, 0.0000, 0.0000, 0.0000, 0.1250,
        0.0000, 0.0000, 0.1250, 0.0000], device='cuda:0',
       grad_fn=<DiagonalBackward0_copy>)
torch.Size([400])
Traceback (most recent call last):
  File "/vast/palmer/pi/krishnaswamy_smita/sv496/PointCloudNet/main.py", line 103, in <module>
    model = PointCloudFeatLearning(args.raw_dir, args.kernel_type, args.threshold, args.device).to(args.device)
  File "/vast/palmer/pi/krishnaswamy_smita/sv496/PointCloudNet/models/graph_learning.py", line 123, in __init__
    self.input_dim = self.graph_feat(torch.tensor(self.subsampled_pcs[0], dtype=torch.float).to(device), 0.01).shape[1]
  File "/gpfs/gibbs/project/krishnaswamy_smita/sv496/conda_envs/mfcn/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/vast/palmer/pi/krishnaswamy_smita/sv496/PointCloudNet/models/graph_learning.py", line 100, in forward
    W = 1/(W + eps)
  File "/vast/palmer/pi/krishnaswamy_smita/sv496/PointCloudNet/models/graph_learning.py", line 100, in forward
    W = 1/(W + eps)
  File "/gpfs/gibbs/project/krishnaswamy_smita/sv496/conda_envs/mfcn/lib/python3.9/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/gpfs/gibbs/project/krishnaswamy_smita/sv496/conda_envs/mfcn/lib/python3.9/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit